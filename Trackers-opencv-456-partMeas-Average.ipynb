{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The MIT License (MIT)\n",
    "\n",
    "#Copyright (c) 2020 Juliana T.C. Marcos\n",
    "\n",
    "#THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO\n",
    "#THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE \n",
    "#AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF \n",
    "#CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\n",
    "\n",
    "#This code use methods of the ParticleFilter (PF) class in order to track an object in a video. The PF uses two\n",
    "#measurements providers which are intermitently chosen based on the value of the ssim index of two images. The\n",
    "#first image is a template of the animal to track while the second is the Region of Interest (ROI) surrounding\n",
    "#the previous estimated location of the tracked animal. The measurements providers are a colour image segmentation\n",
    "#technique and  one of the 8 trackers implemented in opencv. The OpenCV's trackers do not update during the colour\n",
    "#image segmentation turn.\n",
    "\n",
    "#The particles are represented in red, the PF estimate of\n",
    "#the tracked animal is represented in green and the animal's bb is represented in blue. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import of useful librairies\n",
    "import math\n",
    "import numpy as np\n",
    "from skimage import measure\n",
    "from ParticleFilter import ParticleFilter\n",
    "import cv2\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tracker = \"BOOSTING\"\n",
    "tracker = \"KCF\"\n",
    "#tracker = \"CSRT\"\n",
    "#tracker = \"MOSSE\"\n",
    "#tracker = \"TLD\"\n",
    "#tracker = \"MIL\"\n",
    "#tracker = \"MEDIANFLOW\"\n",
    "#tracker = \"GOTURN\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Some variables initialization \"\"\"\n",
    "\n",
    "#Number of trials to average\n",
    "Tot=1\n",
    "#Lists for the Tot running outputs averages \n",
    "BB_avg=[]\n",
    "anchor_avg=[]\n",
    "xy_est_avg=[]\n",
    "ssim_avg=[]\n",
    "particles_avg=[]\n",
    "#Video frame width and height\n",
    "frame_width=1920\n",
    "frame_height=1080\n",
    "#number of particles\n",
    "n_particles=2000\n",
    "#noise in sensors' measurements\n",
    "meas_noise=0\n",
    "#Initialization of some important variables\n",
    "\n",
    "font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "text_coord=(10,40)\n",
    "t_size=0.8\n",
    "t_thick=2\n",
    "ssim=0\n",
    "#This value was chosen according to a paper experiment\n",
    "N_thresh=(2*n_particles)/30\n",
    "n_resampling=0\n",
    "#Lists to contain the counters for each trial\n",
    "cis_l=[]\n",
    "track_call_l=[]\n",
    "track_ctr_l=[]\n",
    "n_resampl_l=[]\n",
    "#Initialize variable for shifting the anchor update between first measurements and first estimations\n",
    "anchor_shift=60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data for video cows\n",
    "anchorS=(1250,350)\n",
    "#This threshold helps to filter small contours\n",
    "#It is however important to adapt it to the object scales in the videos\n",
    "Area_thresh=0\n",
    "#This is to choose the type of threshold (between cv2.THRESH_BINARY_INV \n",
    "#and THRESH_BINARY)\n",
    "#for Dark or bright template\n",
    "type_thr=cv2.THRESH_BINARY_INV\n",
    "#type_thr=cv2.THRESH_BINARY\n",
    "#std in the prediction of particles for the object's position\n",
    "std=10\n",
    "#Capture video where object tracking should be performed\n",
    "videoIn_name=\"./Inputs/cows.avi\"\n",
    "path=\"./Outputs/\"\n",
    "videoOut_name=path+\"cows-pf-ssim-colour-\"+tracker+\"p.avi\"\n",
    "template = cv2.imread('./Inputs/template2.png')\n",
    "template2 = cv2.imread('./Inputs/template2_grass.png')\n",
    "chg_thres=0.6\n",
    "height, width =120,260\n",
    "#Motion model's speed in x and y directions\n",
    "v_x=0.01\n",
    "v_y=0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fyi,fxi=template2.shape[0],template2.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 56801,
     "status": "ok",
     "timestamp": 1579782042429,
     "user": {
      "displayName": "Juliana Thomasia Chakirath Marcos",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mBi57pn5YLYNbvs4CWoUwr5qczRkiGsQZoz-qFs=s64",
      "userId": "11545008696825308510"
     },
     "user_tz": -120
    },
    "id": "uph0UIjRbSHH",
    "outputId": "19e9b6ef-284a-4a79-b6b7-1e51d3ec0078"
   },
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "for num in range(Tot):\n",
    "    #List for averaging running outputs\n",
    "    BB_l=[]\n",
    "    anchor_l=[]\n",
    "    xy_est_l=[]\n",
    "    ssim_l=[]\n",
    "    particles_l=[]\n",
    "    #Counters\n",
    "    cis=0\n",
    "    track_call=0\n",
    "    track_ctr=0\n",
    "    it=0\n",
    "    n_resampling=0\n",
    "    #A single program variables initialization\n",
    "    anchor=anchorS\n",
    "    #Initialization of measurements variables\n",
    "    x_objMeasure,y_objMeasure=anchor[0],anchor[1]\n",
    "    #Initialization of some important variables\n",
    "    ssim=0\n",
    "    #BB variable initialization\n",
    "    BB=0,0,0,0\n",
    "    BB_t=0,0,0,0\n",
    "    #Capture video where object tracking should be performed\n",
    "    video = cv2.VideoCapture(videoIn_name)\n",
    "    #Video output\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "    video_output = cv2.VideoWriter(videoOut_name,fourcc,60,(frame_width,frame_height))\n",
    "    #Particles Instantiation\n",
    "    particles=ParticleFilter(frame_width,frame_height, n_particles)\n",
    "    \n",
    "    if tracker == \"BOOSTING\":\n",
    "        track = cv2.TrackerBoosting_create()\n",
    "    elif tracker == \"KCF\":\n",
    "        track = cv2.TrackerKCF_create()\n",
    "    elif tracker == \"MIL\":\n",
    "        track = cv2.TrackerMIL_create()\n",
    "    elif tracker == \"MOSSE\":\n",
    "        track = cv2.TrackerMOSSE_create()\n",
    "    elif tracker == \"TLD\":\n",
    "        track = cv2.TrackerTLD_create()\n",
    "    elif tracker == \"CSRT\":\n",
    "        track = cv2.TrackerCSRT_create()\n",
    "    elif tracker == \"MEDIANFLOW\":\n",
    "        track = cv2.TrackerMedianFlow_create()\n",
    "    else :\n",
    "        track = cv2.TrackerGOTURN_create()\n",
    "\n",
    "    \n",
    "    #This function uses opencv functions to identify the center of the animal to track\n",
    "    def sensors_measurements(template,img,anchor,meas_noise=3,kernel=3):\n",
    "\n",
    "        #Compute the mean color of the template containing the animal to track color\n",
    "        meanStdTemplate=cv2.meanStdDev(template)\n",
    "\n",
    "        #Convert the color of the frame to work on and apply the GaussianBlur function in order to remove\n",
    "        #Gaussian noise, smooth image and somrtimes highlight edges\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        img = cv2.GaussianBlur(img, (kernel, kernel), 0)\n",
    "\n",
    "        #Binarize frame using the color mean of the animal in such a way that matching parts\n",
    "        #of the frame will appear white and other parts will appear black\n",
    "        ret,thresh = cv2.threshold(img,meanStdTemplate[0][1],255,type_thr)\n",
    "\n",
    "        # find contours in the thresholded image. The if condition is used to avoid error that happens depending\n",
    "        #on the python version used. The middle parameter is to only retrieve parent contours while the latter\n",
    "        #is to avoid redundant points in contours.\n",
    "        cnts = cv2.findContours(thresh.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        contours = cnts[0] if len(cnts) == 2 else cnts[1]\n",
    "\n",
    "        #Compute the contours areas\n",
    "        contoursAreas=[cv2.contourArea(c) for c in contours]\n",
    "\n",
    "        #Compute the center and the BB of the contours\n",
    "        contoursCenter=[]\n",
    "        contoursBB=[]\n",
    "\n",
    "        for c in range(len(contours)):\n",
    "            M = cv2.moments(contours[c])\n",
    "            #If the area of the current contour exists and is greater than a threshold for areas \n",
    "            if M[\"m00\"] != 0 and contoursAreas[c]>Area_thresh:\n",
    "                cX = int(M[\"m10\"] / M[\"m00\"])\n",
    "                cY = int(M[\"m01\"] / M[\"m00\"])\n",
    "                contoursCenter.append((c,cX,cY,contoursAreas[c]))\n",
    "                contoursBB.append(cv2.boundingRect(contours[c]))\n",
    "\n",
    "        #Compute the distance between each center and the anchor center in order to find \n",
    "        #the most suitable shape to track i.e the closest one to the anchor\n",
    "\n",
    "        contoursAnchorDist=[math.sqrt((contoursCenter[i][1]-anchor[0])**2+\\\n",
    "        (contoursCenter[i][2]-anchor[1])**2) for i in range (len(contoursCenter))]\n",
    "\n",
    "        #Save and return the coordinates of the most suitable center and its contours\n",
    "        index=contoursAnchorDist.index(min(contoursAnchorDist))\n",
    "        cX=contoursCenter[index][1]+np.random.standard_normal()*meas_noise\n",
    "        cY=contoursCenter[index][2]+np.random.standard_normal()*meas_noise\n",
    "\n",
    "        return cX,cY,contoursBB[index]\n",
    "\n",
    "    #Loop through the entire video\n",
    "    while (True):\n",
    "        #Take the video and break it frame by frame\n",
    "        _,frame=video.read()\n",
    "        #Check if frames are captured\n",
    "        if(_ == False ): break\n",
    "\n",
    "        it+=1\n",
    "        \n",
    "        #initialization of opencv tracker\n",
    "        if it==1 and _==True:\n",
    "            BB_t=(int(anchor[0]-width/2),int(anchor[1]-height/2),width,height)\n",
    "            track.init(frame,BB_t)\n",
    "            \n",
    "        #Particles prediction update\n",
    "        particles.particles_update(v_x,v_y,std,frame_width,frame_height)\n",
    "        particles_l.append(particles.particles.copy())\n",
    "        anchor_l.append(anchor)\n",
    "    \n",
    "        #Take dimensions of ROI around animal in current frame for SSIM evaluation with \n",
    "        #template\n",
    "        ROI_ssim=(int(anchor[0]-fxi/2),int(anchor[1]-fyi/2),fxi,fyi)\n",
    "        frame_crop=frame[ROI_ssim[1]:ROI_ssim[1]+ROI_ssim[3],ROI_ssim[0]:ROI_ssim[0]+ROI_ssim[2]]\n",
    "        fy,fx=frame_crop.shape[0],frame_crop.shape[1]\n",
    "    \n",
    "        #Here, we check if the dimensions of the ROI around the animal and the template are the same\n",
    "        #to select the cis if not, because these cases correspond to the frame boundaries. Therefore, \n",
    "        #the ROI might not contain sufficient information to allow the change detection with the ssim.\n",
    "        if ((fxi!=fx) or (fyi!=fy)):\n",
    "            ssim=1.1\n",
    "        else: \n",
    "            #The value 3 is the minimum dimension for images to compute the ssim index\n",
    "            if ((fxi>3 and fyi>3)): \n",
    "                ssim=measure.compare_ssim(frame_crop,template2, \\\n",
    "                                              multichannel=True,win_size=3)\n",
    "            else:\n",
    "                ssim=0.0\n",
    "        \n",
    "        ssim=abs(ssim)\n",
    "        ssim_l.append(ssim)\n",
    "        \n",
    "        if (ssim<chg_thres):\n",
    "            track_call+=1\n",
    "            #If a potential change is detected, call a method other than the cis to provide measurements to the PF\n",
    "            cont, BB_t = track.update(frame)\n",
    "            if cont==True:\n",
    "                x_objMeasure,y_objMeasure=BB_t[0]+BB_t[2]/2,BB_t[1]+BB_t[3]/2\n",
    "                BB=int(BB_t[0]),int(BB_t[1]),int(BB_t[2]),int(BB_t[3])\n",
    "                #anchor=x_objMeasure,y_objMeasure\n",
    "                \n",
    "                track_ctr+=1\n",
    "                print(\"step: \",it,\" x_objMeasure \",x_objMeasure,\" y_objMeasure \",y_objMeasure,\" BB_t \",BB_t)\n",
    "\n",
    "            cv2.putText(frame,'Change detected call '+tracker+' : SSIM = '+str(ssim),text_coord,font,t_size,(255,255,255),t_thick,cv2.LINE_AA)\n",
    "            \n",
    "        else :\n",
    "            #Measurements\n",
    "            x_objMeasure,y_objMeasure,BB = sensors_measurements(template,frame,anchor,meas_noise) \n",
    "            cis+=1\n",
    "            print(\"step: \",it,\" x_objMeasure \",x_objMeasure,\" y_objMeasure \",y_objMeasure,\" BB \",BB)\n",
    "\n",
    "            cv2.putText(frame,'No Change detected, use CIS: SSIM = '+str(ssim),text_coord,font,t_size,(255,255,255),t_thick,cv2.LINE_AA)   \n",
    "           \n",
    "            \n",
    "        #Save BB in a list and anchor in another list\n",
    "        BB_l.append(BB)\n",
    "        \n",
    "        #Update the particles weights with the new measurement\n",
    "        particles.weigth_update(x_objMeasure,y_objMeasure)\n",
    "\n",
    "        #Estimation of object center position\n",
    "        x_estimation,y_estimation=particles.position_estimation()\n",
    "        print(\"step: \",it,\" x_estimation \",x_estimation,\" y_estimation \",y_estimation)\n",
    "        \n",
    "        #Save the x and y estimated in a list\n",
    "        xy_est_l.append((x_estimation,y_estimation))\n",
    "\n",
    "        #Draw the particles\n",
    "        particles.draw_box_particles(frame,BB,x_estimation,y_estimation)\n",
    "        #Draw the position estimation\n",
    "        cv2.circle(frame,(x_estimation,y_estimation),5,[0,255,0],3)\n",
    "\n",
    "        #Update the anchor with either the current measurements or the x and y estimates\n",
    "        if it > anchor_shift:\n",
    "            anchor=x_estimation,y_estimation\n",
    "        else:\n",
    "            anchor=x_objMeasure,y_objMeasure\n",
    "        \n",
    "        #Resample the particles\n",
    "\n",
    "        if (particles.effective_particles() < N_thresh):\n",
    "            n_resampling+=1\n",
    "            particles.resampling()\n",
    "\n",
    "        if (num==Tot-1):\n",
    "            video_output.write(frame)\n",
    "            \n",
    "        #Reinitialize BB to avoid cis' bb drawing when the tracker does not track\n",
    "        BB=0,0,0,0\n",
    "\n",
    "        #if it==50:\n",
    "        #    break\n",
    "        \n",
    "    #List for the number of resampling, cis counters,track_call and track_ctr    \n",
    "    n_resampl_l.append(n_resampling)\n",
    "    cis_l.append(cis)\n",
    "    track_call_l.append(track_call)\n",
    "    track_ctr_l.append(track_ctr)\n",
    "    BB_avg.append(BB_l)\n",
    "    xy_est_avg.append(xy_est_l)\n",
    "    ssim_avg.append(ssim_l)\n",
    "    particles_avg.append(particles_l)\n",
    "    anchor_avg.append(anchor_l)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1290,
     "status": "ok",
     "timestamp": 1579782048265,
     "user": {
      "displayName": "Juliana Thomasia Chakirath Marcos",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mBi57pn5YLYNbvs4CWoUwr5qczRkiGsQZoz-qFs=s64",
      "userId": "11545008696825308510"
     },
     "user_tz": -120
    },
    "id": "eIdZ-33dYmtS",
    "outputId": "b8a08eda-c1e4-46be-a506-ef7c061f2860"
   },
   "outputs": [],
   "source": [
    "prog_duration= time.time() - start_time\n",
    "prog_duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1413,
     "status": "ok",
     "timestamp": 1579782050004,
     "user": {
      "displayName": "Juliana Thomasia Chakirath Marcos",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mBi57pn5YLYNbvs4CWoUwr5qczRkiGsQZoz-qFs=s64",
      "userId": "11545008696825308510"
     },
     "user_tz": -120
    },
    "id": "h1exhSim-F-k",
    "outputId": "d50940e0-7762-4329-9ad2-57a25f88ba17"
   },
   "outputs": [],
   "source": [
    "prog_duration/60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prog_duration/(60*Tot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(n_resampl_l)/Tot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(BB_l),len(xy_est_l),len(BB_avg),len(xy_est_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(BB_l),len(xy_est_l),len(BB_avg),len(xy_est_avg),len(particles_avg),len(ssim_avg),\\\n",
    "len(anchor_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(cis_l)/Tot,sum(track_call_l)/Tot,sum(track_ctr_l)/Tot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BB_l_avg=[] \n",
    "BB_avg=np.array(BB_avg)\n",
    "BB_l_avg=np.sum(BB_avg,0)/Tot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xy_est_l_avg=[] \n",
    "xy_est_avg=np.array(xy_est_avg)\n",
    "xy_est_l_avg=np.sum(xy_est_avg,0)/Tot\n",
    "xy_est_l_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ssim_l_avg=[] \n",
    "ssim_avg=np.array(ssim_avg)\n",
    "ssim_l_avg=np.sum(ssim_avg,0)/Tot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "particles_l_avg=[] \n",
    "particles_avg=np.array(particles_avg)\n",
    "particles_l_avg=np.sum(particles_avg,0)/Tot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anchor_l_avg=[] \n",
    "anchor_avg=np.array(anchor_avg)\n",
    "anchor_l_avg=np.sum(anchor_avg,0)/Tot\n",
    "anchor_l_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#xy_est_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#BB_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(path+'xy_data2_'+tracker+'p.npy',np.array(xy_est_l_avg))\n",
    "np.save(path+'BB_data2_'+tracker+'p.npy',np.array(BB_l_avg))\n",
    "np.save(path+'ssim_data2_'+tracker+'p.npy',np.array(ssim_l_avg))\n",
    "np.save(path+'part_data2_'+tracker+'p.npy',np.array(particles_l_avg))\n",
    "np.save(path+'anchor_data2_'+tracker+'p.npy',np.array(anchor_l_avg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "ParticleFilter-data-yolo-roi.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
