{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The MIT License (MIT)\n",
    "\n",
    "#Copyright (c) 2020 Juliana T.C. Marcos\n",
    "\n",
    "#THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO\n",
    "#THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE \n",
    "#AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF \n",
    "#CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\n",
    "\n",
    "#This code use methods of the ParticleFilter (PF) class in order to track an object in a video. The PF uses as\n",
    "#measurements provider a colour image segmentation technique.\n",
    "\n",
    "#The particles are represented in red, the PF estimate of\n",
    "#the tracked animal is represented in green and the animal's bb is represented in blue. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import of useful librairies\n",
    "import cv2\n",
    "import math\n",
    "import numpy as np\n",
    "from skimage import measure\n",
    "from ParticleFilter import ParticleFilter\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Some variables initialization \"\"\"\n",
    "#The total number of trials\n",
    "Tot=1\n",
    "#Lists for the Tot running outputs averages \n",
    "BB_avg=[]\n",
    "anchor_avg=[]\n",
    "xy_est_avg=[]\n",
    "particles_avg=[]\n",
    "#number of particles\n",
    "n_particles=2000\n",
    "#noise in sensors' measurements\n",
    "meas_noise=0\n",
    "font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "text_coord=(10,40)\n",
    "t_size=0.8\n",
    "t_thick=2\n",
    "#Lists to contain the counters for each trial\n",
    "cis_l=[]\n",
    "n_resampl_l=[]\n",
    "\n",
    "#This value was chosen according to a paper experiment\n",
    "N_thresh=(2*n_particles)/30\n",
    "#Video frame width and height\n",
    "frame_width=1920\n",
    "frame_height=1080\n",
    "#Initialize variable for shifting the anchor update between first measurements and first estimations\n",
    "anchor_shift=60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data for video cows\n",
    "anchorS=(1250,350)\n",
    "#This threshold helps to filter small contours\n",
    "#It is however important to adapt it to the object scales in the videos\n",
    "Area_thresh=0\n",
    "#This is to choose the type of threshold (between cv2.THRESH_BINARY_INV \n",
    "#and THRESH_BINARY)\n",
    "type_thr=cv2.THRESH_BINARY_INV\n",
    "#Capture video where object tracking should be performed\n",
    "path=\"./Outputs/\"\n",
    "videoIn_name =\"./Inputs/cows.avi\"\n",
    "videoOut_name =path+\"cows-pf-colour.avi\"\n",
    "template = cv2.imread('./Inputs/template2.png')\n",
    "#number of particles\n",
    "n_particles=2000\n",
    "#std in the prediction of particles for the object's position\n",
    "std=10\n",
    "#Motion model's speed in x and y directions\n",
    "v_x=0.01\n",
    "v_y=0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 56801,
     "status": "ok",
     "timestamp": 1579782042429,
     "user": {
      "displayName": "Juliana Thomasia Chakirath Marcos",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mBi57pn5YLYNbvs4CWoUwr5qczRkiGsQZoz-qFs=s64",
      "userId": "11545008696825308510"
     },
     "user_tz": -120
    },
    "id": "uph0UIjRbSHH",
    "outputId": "19e9b6ef-284a-4a79-b6b7-1e51d3ec0078"
   },
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "for num in range(Tot):\n",
    "    #List for averaging running outputs\n",
    "    BB_l=[]\n",
    "    anchor_l=[]\n",
    "    xy_est_l=[]\n",
    "    particles_l=[]\n",
    "    #Counters initialization\n",
    "    cis=0\n",
    "    it=0\n",
    "    n_resampling=0\n",
    "    anchor=anchorS\n",
    "    #Initialization of measurements variables\n",
    "    x_objMeasure,y_objMeasure=anchor[0],anchor[1]\n",
    "    #BB variable initialization\n",
    "    BB=0,0,0,0\n",
    "    #Capture video where object tracking should be performed\n",
    "    video = cv2.VideoCapture(videoIn_name)\n",
    "    #Video output\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "    video_output = cv2.VideoWriter(videoOut_name,fourcc,60,(frame_width,frame_height))\n",
    "    #Particles Instantiation\n",
    "    particles=ParticleFilter(frame_width,frame_height, n_particles)\n",
    "\n",
    "\n",
    "    #This function uses open cv function to identify the center of the animal to track\n",
    "    def sensors_measurements(template,img,anchor,mea_noise=3,kernel=3):\n",
    "\n",
    "        #Compute the mean color of the template containing the animal to track color\n",
    "        meanStdTemplate=cv2.meanStdDev(template)\n",
    "\n",
    "        #Convert the color of the frame to work on and apply the GaussianBlur function in order to remove\n",
    "        #Gaussian noise, smooth image and somrtimes highlight edges\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        img = cv2.GaussianBlur(img, (kernel, kernel), 0)\n",
    "\n",
    "        #Binarize frame using the color mean of the animal in such a way that matching parts\n",
    "        #of the frame will appear white and other parts will appear black\n",
    "        ret,thresh = cv2.threshold(img,meanStdTemplate[0][1],255,type_thr)\n",
    "\n",
    "        # find contours in the thresholded image. The if condition is used to avoid error that happens depending\n",
    "        #on the python version used. The middle parameter is to only retrieve parent contours while the latter\n",
    "        #is to avoid redundant points in contours.\n",
    "        cnts = cv2.findContours(thresh.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        contours = cnts[0] if len(cnts) == 2 else cnts[1]\n",
    "\n",
    "        #Compute the contours areas\n",
    "        contoursAreas=[cv2.contourArea(c) for c in contours]\n",
    "\n",
    "        #Compute the center and the BB of the contours\n",
    "        contoursCenter=[]\n",
    "        contoursBB=[]\n",
    "\n",
    "        for c in range(len(contours)):\n",
    "            M = cv2.moments(contours[c])\n",
    "            #If the area of the current contour exists and is greater than a threshold for areas \n",
    "            if M[\"m00\"] != 0 and contoursAreas[c]>Area_thresh:\n",
    "                cX = int(M[\"m10\"] / M[\"m00\"])\n",
    "                cY = int(M[\"m01\"] / M[\"m00\"])\n",
    "                contoursCenter.append((c,cX,cY,contoursAreas[c]))\n",
    "                contoursBB.append(cv2.boundingRect(contours[c]))\n",
    "\n",
    "        #Compute the distance between each center and the anchor center in order to find \n",
    "        #the most suitable shape to track i.e the closest one to the anchor\n",
    "\n",
    "        contoursAnchorDist=[math.sqrt((contoursCenter[i][1]-anchor[0])**2+\\\n",
    "        (contoursCenter[i][2]-anchor[1])**2) for i in range (len(contoursCenter))]\n",
    "\n",
    "        #Save and return the coordinates of the most suitable center and its contours\n",
    "        index=contoursAnchorDist.index(min(contoursAnchorDist))\n",
    "        cX=contoursCenter[index][1]+np.random.standard_normal()*meas_noise\n",
    "        cY=contoursCenter[index][2]+np.random.standard_normal()*meas_noise\n",
    "\n",
    "        return cX,cY,contoursBB[index]\n",
    "\n",
    "    #Loop through the entire video\n",
    "    while (True):\n",
    "        #Take the video and break it frame by frame\n",
    "        _,frame=video.read()\n",
    "        #Check if frames are captured\n",
    "        if(_ == False ): break\n",
    "\n",
    "        it+=1\n",
    "\n",
    "        #Particles prediction update\n",
    "        particles.particles_update(v_x,v_y,std,frame_width,frame_height)\n",
    "        particles_l.append(particles.particles.copy())\n",
    "        anchor_l.append(anchor)\n",
    "\n",
    "        #Measurements\n",
    "        x_objMeasure,y_objMeasure,BB = sensors_measurements(template,frame,anchor,meas_noise)\n",
    "        #Use anchor to select the closest area and then the actual tracked target\n",
    "        cis+=1\n",
    "        #Save BB in a list\n",
    "        BB_l.append(BB)\n",
    "        \n",
    "        #Update the particles weights with the new measurements (Object center)\n",
    "        particles.weigth_update(x_objMeasure,y_objMeasure)\n",
    "\n",
    "        #Estimation of object center position\n",
    "        x_estimation,y_estimation=particles.position_estimation()\n",
    "\n",
    "        #Save the x and y estimated in a list\n",
    "        xy_est_l.append((x_estimation,y_estimation))\n",
    "\n",
    "        #Draw the particles\n",
    "        particles.draw_box_particles(frame,BB,x_estimation,y_estimation)\n",
    "        \n",
    "        #Draw the position estimation\n",
    "        cv2.circle(frame,(x_estimation,y_estimation),5,[0,255,0],3)\n",
    "       \n",
    "        #Update the anchor with either the current measurements or the x and y estimates\n",
    "        if it > anchor_shift:\n",
    "            anchor=x_estimation,y_estimation\n",
    "        else:\n",
    "            anchor=x_objMeasure,y_objMeasure\n",
    "        \n",
    "\n",
    "        #Resample the particles\n",
    "        if (particles.effective_particles() < N_thresh):\n",
    "            n_resampling+=1\n",
    "            particles.resampling()\n",
    "\n",
    "        if (num==Tot-1):\n",
    "            video_output.write(frame)\n",
    "\n",
    "        #if it==50:\n",
    "        #    break\n",
    "\n",
    "    \n",
    "    \n",
    "    cis_l.append(cis)\n",
    "    n_resampl_l.append(n_resampling)\n",
    "    BB_avg.append(BB_l)\n",
    "    xy_est_avg.append(xy_est_l)\n",
    "    particles_avg.append(particles_l)\n",
    "    anchor_avg.append(anchor_l)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1290,
     "status": "ok",
     "timestamp": 1579782048265,
     "user": {
      "displayName": "Juliana Thomasia Chakirath Marcos",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mBi57pn5YLYNbvs4CWoUwr5qczRkiGsQZoz-qFs=s64",
      "userId": "11545008696825308510"
     },
     "user_tz": -120
    },
    "id": "eIdZ-33dYmtS",
    "outputId": "b8a08eda-c1e4-46be-a506-ef7c061f2860"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37.86215567588806"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prog_duration= time.time() - start_time\n",
    "prog_duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6310359279314677"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prog_duration/(60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1413,
     "status": "ok",
     "timestamp": 1579782050004,
     "user": {
      "displayName": "Juliana Thomasia Chakirath Marcos",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mBi57pn5YLYNbvs4CWoUwr5qczRkiGsQZoz-qFs=s64",
      "userId": "11545008696825308510"
     },
     "user_tz": -120
    },
    "id": "h1exhSim-F-k",
    "outputId": "d50940e0-7762-4329-9ad2-57a25f88ba17"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6310359279314677"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prog_duration/(60*Tot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "456.0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(n_resampl_l)/Tot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(980, 980, 1, 1, 1, 1)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(BB_l),len(xy_est_l),len(BB_avg),len(xy_est_avg),len(particles_avg),len(anchor_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "980.0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(cis_l)/Tot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "BB_l_avg=[] \n",
    "BB_avg=np.array(BB_avg)\n",
    "BB_l_avg=np.sum(BB_avg,0)/Tot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1138.,  466.],\n",
       "       [1228.,  395.],\n",
       "       [1243.,  367.],\n",
       "       ...,\n",
       "       [1310.,  340.],\n",
       "       [1311.,  341.],\n",
       "       [1310.,  341.]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xy_est_l_avg=[] \n",
    "xy_est_avg=np.array(xy_est_avg)\n",
    "xy_est_l_avg=np.sum(xy_est_avg,0)/Tot\n",
    "xy_est_l_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "particles_l_avg=[] \n",
    "particles_avg=np.array(particles_avg)\n",
    "particles_l_avg=np.sum(particles_avg,0)/Tot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1250.,  350.],\n",
       "       [1250.,  364.],\n",
       "       [1252.,  364.],\n",
       "       ...,\n",
       "       [1310.,  340.],\n",
       "       [1310.,  340.],\n",
       "       [1311.,  341.]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anchor_l_avg=[] \n",
    "anchor_avg=np.array(anchor_avg)\n",
    "anchor_l_avg=np.sum(anchor_avg,0)/Tot\n",
    "anchor_l_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#xy_est_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#BB_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(path+'xy_data1.npy',np.array(xy_est_l_avg))\n",
    "np.save(path+'BB_data1.npy',np.array(BB_l_avg))\n",
    "np.save(path+'part_data1.npy',np.array(particles_l_avg))\n",
    "np.save(path+'anchor_data1.npy',np.array(anchor_l_avg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "980"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(BB_l_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "980"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(xy_est_l_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "ParticleFilter-data-yolo-roi.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
