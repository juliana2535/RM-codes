{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The MIT License (MIT)\n",
    "\n",
    "#Copyright (c) 2020 Juliana T.C. Marcos\n",
    "\n",
    "#THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO\n",
    "#THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE \n",
    "#AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF \n",
    "#CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\n",
    "\n",
    "#This code use methods of the ParticleFilter (PF) class in order to track an object in a video. The PF uses as\n",
    "#measurements provider the You Only Look Once (YOLO) object detector. \n",
    "\n",
    "#The particles are represented in red, the PF estimate of\n",
    "#the tracked animal is represented in green and the animal's bb is represented in blue. \n",
    "\n",
    "#Thanks to Nayak for the nice tutorial about using YOLOv3 with OpenCv which is available at this address:\n",
    "#https://www.learnopencv.com/deep-learning-based-object-detection-using-yolov3-with-opencv-python-c/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import of useful librairies\n",
    "import cv2\n",
    "import math\n",
    "import numpy as np\n",
    "from skimage import measure\n",
    "from ParticleFilter import ParticleFilter\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Some variables initialization \"\"\"\n",
    "\n",
    "#The total number of trials\n",
    "Tot=1\n",
    "#Lists for the Tot running outputs averages \n",
    "BB_avg=[]\n",
    "ROI_avg=[]\n",
    "anchor_avg=[]\n",
    "xy_est_avg=[]\n",
    "particles_avg=[]\n",
    "#number of particles\n",
    "n_particles=2000\n",
    "#noise in sensors' measurements\n",
    "meas_noise=0\n",
    "#Read weights and config files to create YOLO(v3) net\n",
    "net = cv2.dnn.readNet(\"./Inputs/yolov3.weights\", \"./Inputs/yolov3.cfg\")\n",
    "#Fetch the three output layers names of YOLO net, they are the ones not connected to \n",
    "#any following layers since they are the last layers\n",
    "layer_names = net.getLayerNames()\n",
    "output_layer_names = [layer_names[i[0] - 1] for i in net.getUnconnectedOutLayers()]\n",
    "#Read the classes in coco.names file for YOLO net\n",
    "coco_classes = []\n",
    "with open ('./Inputs/coco.names','r') as file:\n",
    "    coco_classes=[line.strip(\"\\n\") for line in file.readlines()]\n",
    "\n",
    "font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "text_coord=(10,40)\n",
    "t_size=0.8\n",
    "t_thick=2\n",
    "#This value was chosen according to a paper experiment\n",
    "N_thresh=(2*n_particles)/30\n",
    "#Scale for YOLO's inputs preprocessing\n",
    "scale=1/255\n",
    "#Video frame width and height\n",
    "frame_width=1920\n",
    "frame_height=1080\n",
    "#Lists to contain the counters for each trial\n",
    "yolo_det_l=[]\n",
    "n_resampl_l=[]\n",
    "#Initialize variable for shifting the anchor update between first measurements and first estimations\n",
    "anchor_shift=60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data for video cows\n",
    "anchorS=(1250,350)\n",
    "videoIn_name=\"./Inputs/cows.avi\"\n",
    "path=\"./Outputs/\"\n",
    "videoOut_name=path+\"cows-pf-yolo.avi\"\n",
    "#std in the prediction of particles for the object's position\n",
    "std=10\n",
    "#These are YOLO parameters\n",
    "conf=0.8\n",
    "nms=0.7\n",
    "height, width, channels =224,320,3\n",
    "blob_x,blob_y=224,320\n",
    "#Motion model's speed in x and y directions\n",
    "v_x=0.01\n",
    "v_y=0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fxPp5m4VDz09"
   },
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "for num in range(Tot):\n",
    "\n",
    "    #List for averaging running outputs\n",
    "    BB_l=[]\n",
    "    ROI_l=[]\n",
    "    anchor_l=[]\n",
    "    xy_est_l=[]\n",
    "    particles_l=[]\n",
    "    #Counters\n",
    "    yolo_det=0\n",
    "    it=0\n",
    "    n_resampling=0\n",
    "    #A single program variables initialization\n",
    "    anchor=anchorS\n",
    "    #Initialization of measurements variables\n",
    "    x_objMeasure,y_objMeasure=anchor[0],anchor[1]\n",
    "    #BB variable initialization\n",
    "    BB=0,0,0,0\n",
    "    #Capture video where object tracking should be performed\n",
    "    video = cv2.VideoCapture(videoIn_name)\n",
    "    #Video output\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "    video_output = cv2.VideoWriter(videoOut_name,fourcc,60,(frame_width,frame_height))\n",
    "    #Particles Instantiation\n",
    "    particles=ParticleFilter(frame_width,frame_height, n_particles)\n",
    "    \n",
    "    #Loop through the entire video\n",
    "    while (True):\n",
    "        #Take the video and break it frame by frame\n",
    "        _,frame=video.read()\n",
    "        #Check if frames are captured\n",
    "        if(_ == False ): break\n",
    "\n",
    "        it+=1\n",
    "\n",
    "        #Particles prediction update\n",
    "        particles.particles_update(v_x,v_y,std,frame_width,frame_height)\n",
    "        particles_l.append(particles.particles.copy())\n",
    "        anchor_l.append(anchor)\n",
    "    \n",
    "        #Coordinates of ROI around anchor\n",
    "        dy1=int(anchor[1]-height/2)\n",
    "        #if(dy1<0):dy1=0\n",
    "        dy2=int(anchor[1]+height/2)\n",
    "        #if (dy2>frame_height):dy2=frame_height\n",
    "        dx1=int(anchor[0]-width/2)\n",
    "        #if (dx1<0): dx1=0\n",
    "        dx2=int(anchor[0]+width/2)\n",
    "        #if (dx2>frame_width):dx2=frame_width\n",
    "\n",
    "        frame_roi=frame[dy1:dy2,dx1:dx2]\n",
    "        ROI_l.append((dx1,dy1,dx2,dy2))\n",
    "            \n",
    "\n",
    "        # Detecting objects\n",
    "        scale=1/255\n",
    "        blob = cv2.dnn.blobFromImage(frame_roi,scale,(blob_x, blob_y),(0, 0, 0), True, crop=False)\n",
    "        net.setInput(blob)\n",
    "        #Run forward pass to get predictions from output layers selected\n",
    "        outputs = net.forward(output_layer_names)\n",
    "        # Showing informations on the screen\n",
    "        classes = []\n",
    "        confidences = []\n",
    "        boxes = []\n",
    "        yolo_center=[]\n",
    "        yolo_center_anchor_dist=[]\n",
    "\n",
    "        #for each output of the YOLO last layers\n",
    "        for output in outputs:\n",
    "            for detection in output:\n",
    "            #Each detection contains center point x,y,width,height,object probability\n",
    "            #and 80 class probability\n",
    "                scores = detection[5:]\n",
    "                class_id = np.argmax(scores)\n",
    "                confidence = scores[class_id]\n",
    "                if confidence > conf:\n",
    "                    print(\"step \",str(it),\"confidence \",confidence,\"\\n\")\n",
    "                    #non normalized detected object's center, width and height \n",
    "                    center_x,center_y = int(detection[0] *blob_x),int(detection[1] * blob_y)\n",
    "                    w,h = int(detection[2] * blob_x),int(detection[3] * blob_y)\n",
    "                    # Rectangle coordinates for drawing\n",
    "                    x,y = int(center_x - w / 2),int(center_y - h / 2)\n",
    "                    boxes.append([x, y, w, h])\n",
    "                    confidences.append(float(confidence))\n",
    "                    classes.append(class_id)\n",
    "\n",
    "                    #Get coordinates in initial video frame reference instead of \n",
    "                    #ROI reference\n",
    "                    center_x_reverse=center_x+(anchor[0]-width/2)\n",
    "                    center_y_reverse=center_y+(anchor[1]-height/2)\n",
    "                    yolo_center.append((center_x_reverse,center_y_reverse))\n",
    "\n",
    "        #Search and keep relevant bounding boxes given their scores \n",
    "        indexes = cv2.dnn.NMSBoxes(boxes, confidences, conf, nms)\n",
    "        #Only compute the distances between anchor and the yolo predictions\n",
    "        #if confidence is good and indexes is not empty\n",
    "        if (len(indexes)!=0):\n",
    "            yolo_center_anchor_dist=[math.sqrt((yolo_center[i][0]-anchor[0])**2+\\\n",
    "            (yolo_center[i][1]-anchor[1])**2) for i in range (len(yolo_center))\\\n",
    "                                    if i in indexes]\n",
    "            #Keep the relevant indices in a list to retrieve the relevant index latter\n",
    "            nms_indexes=[i for i in range (len(yolo_center)) if i in indexes]\n",
    "\n",
    "            print(\"step \",str(it),\"indexes \",indexes,\" nms \",nms_indexes,\\\n",
    "            \" yolo_center \",yolo_center,\" distances \", yolo_center_anchor_dist, \"\\n\")\n",
    "\n",
    "            #Save and return the coordinates of the most suitable center and its BB\n",
    "            #Keep the index of the minimum distance between prediction and anchor\n",
    "            index=yolo_center_anchor_dist.index(min(yolo_center_anchor_dist))\n",
    "            #Retrieve relevant index to select the yolo index and the corresponding BB\n",
    "            index_yolo=nms_indexes[index]\n",
    "            print(\"step \",str(it),\" index \",index,\" index_yolo \",index_yolo,\"\\n\")\n",
    "            BB_x=int(boxes[index_yolo][0]+(anchor[0]-width/2))\n",
    "            BB_y=int(boxes[index_yolo][1]+(anchor[1]-height/2))\n",
    "            BB =BB_x,BB_y,boxes[index_yolo][2],boxes[index_yolo][3]\n",
    "\n",
    "            #Update measurements and anchor  \n",
    "            x_objMeasure,y_objMeasure=yolo_center[index_yolo][0],yolo_center[index_yolo][1]\n",
    "            yolo_det+=1\n",
    "\n",
    "        #Save BB in a list\n",
    "        BB_l.append(BB)\n",
    "        \n",
    "        #Draw the ROI in red\n",
    "        cv2.rectangle(frame, (dx1,dy1), (dx2,dy2), (0,0,250), 2)\n",
    "\n",
    "        #Update the particles weights with the new measurements (Object center)\n",
    "        particles.weigth_update(x_objMeasure,y_objMeasure)\n",
    "\n",
    "        #Estimation of object center position\n",
    "        x_estimation,y_estimation=particles.position_estimation()\n",
    "        \n",
    "        #Update the anchor with either the current measurements or the x and y estimates\n",
    "        if it > anchor_shift:\n",
    "            anchor=x_estimation,y_estimation\n",
    "        else:\n",
    "            anchor=x_objMeasure,y_objMeasure\n",
    "        \n",
    "        #Save the x and y estimated in a list\n",
    "        xy_est_l.append((x_estimation,y_estimation))\n",
    "\n",
    "        #Draw the particles\n",
    "        particles.draw_box_particles(frame,BB,x_estimation,y_estimation)\n",
    "        #Draw the position estimation\n",
    "        cv2.circle(frame,(x_estimation,y_estimation),5,[0,255,0],3)\n",
    "\n",
    "        #Resample the particles\n",
    "        if (particles.effective_particles() < N_thresh):\n",
    "            n_resampling+=1\n",
    "            particles.resampling()\n",
    "\n",
    "        if (num==Tot-1):\n",
    "            video_output.write(frame)\n",
    "\n",
    "        #if it==50:\n",
    "        #    break\n",
    "    \n",
    "    yolo_det_l.append(yolo_det) \n",
    "    n_resampl_l.append(n_resampling)\n",
    "    BB_avg.append(BB_l)\n",
    "    xy_est_avg.append(xy_est_l)\n",
    "    particles_avg.append(particles_l)\n",
    "    ROI_avg.append(ROI_l)\n",
    "    anchor_avg.append(anchor_l)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prog_duration= time.time() - start_time\n",
    "prog_duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qoRvtCn6nOvF"
   },
   "outputs": [],
   "source": [
    "prog_duration/60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prog_duration/(60*Tot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(n_resampl_l)/Tot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(BB_l),len(xy_est_l),len(BB_avg),len(xy_est_avg),len(particles_avg),len(anchor_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(yolo_det_l)/Tot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BB_l_avg=[] \n",
    "BB_avg=np.array(BB_avg)\n",
    "BB_l_avg=np.sum(BB_avg,0)/Tot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xy_est_l_avg=[] \n",
    "xy_est_avg=np.array(xy_est_avg)\n",
    "xy_est_l_avg=np.sum(xy_est_avg,0)/Tot\n",
    "xy_est_l_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROI_l_avg=[] \n",
    "ROI_avg=np.array(ROI_avg)\n",
    "ROI_l_avg=np.sum(ROI_avg,0)/Tot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "particles_l_avg=[] \n",
    "particles_avg=np.array(particles_avg)\n",
    "particles_l_avg=np.sum(particles_avg,0)/Tot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anchor_l_avg=[] \n",
    "anchor_avg=np.array(anchor_avg)\n",
    "anchor_l_avg=np.sum(anchor_avg,0)/Tot\n",
    "anchor_l_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#xy_est_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#BB_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(path+'xy_data3.npy',np.array(xy_est_l_avg))\n",
    "np.save(path+'BB_data3.npy',np.array(BB_l_avg))\n",
    "np.save(path+'ROI_data3.npy',np.array(ROI_l_avg))\n",
    "np.save(path+'part_data3.npy',np.array(particles_l_avg))\n",
    "np.save(path+'anchor_data3.npy',np.array(anchor_l_avg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOOtWeyPoOACAsQjofGdQXH",
   "collapsed_sections": [],
   "name": "data_pf_yolo_roi.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
